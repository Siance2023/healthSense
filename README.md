# MaÃ®triser le diabÃ¨te : Comment l'IA peut contribuer Ã  l'amÃ©lioration du contrÃ´le glycÃ©mique ?
![Illustration](doc/Illustration.jpeg)  
---CrÃ©dit ImageÂ : Google AI---

## ğŸ” Motivations
Afin d'analyser l'impact de la composition et de l'Ã©quilibre des repas sur la glycÃ©mie, j'envisage de m'appuyer sur les avancÃ©es de l'Intelligence Artificielle.
L'objectif est d'entrainer un modÃ¨le d'apprentissage par rÃ©seaux de neurones pour tenir compte de la nature des donnÃ©es, peu corrÃ©lÃ©es les unes et autres, et surtout de la complexitÃ© de la tÃ¢che. Tous les experts du domaine consultÃ©s en conviennent. Il s'agit ici de construire un modÃ¨le capable de prÃ©dire la glycÃ©mie postprandiale Ã  partir des valeurs nutritionnelles des repas.

## 1. Premier dÃ©fiÂ : collecter des donnÃ©es prÃ©cises et en quantitÃ© suffisante
Pour cela, il fallait d'abord collecter des mesures, beaucoup de mesuresÂ ! J'ai donc dÃ©cidÃ© de conduire une campagne systÃ©matique de mesures portant sur les valeurs nutritionnelles de tous mes repas (4 repas par jourÂ : petit-dÃ©jeuner, dÃ©jeuner, snack et diner), ainsi que sur les valeurs des glycÃ©mies prÃ©- et postprandiales (soit 8 prÃ©lÃ¨vements par jour). La tÃ¢che la plus ardue consiste Ã  dÃ©terminer les quantitÃ©s des aliments constitutifs des repas et de retrouver leurs apports nutritionnels (glucides, protÃ©ines, lipides, fibres, Ã©nergie (kcal), index glycÃ©mique et charge glycÃ©mique). Bien que ces informations soient documentÃ©es, les sources sont souvent incomplÃ¨tes et divergent notablement. Le premier challenge consiste donc Ã  collecter des donnÃ©es fiables et les plus prÃ©cises possibles.
Cette compagne a Ã©tÃ© conduite sur une pÃ©riode de 2 semaines.

## ğŸ“ DonnÃ©es collectÃ©esÂ :
- NutrimentsÂ : Glucides, Lipides, ProtÃ©ines, Fibres
- Indice glycÃ©mique & charge glycÃ©mique
- EnergieÂ : kcal
- GlycÃ©mie prÃ©- et postprandiale

âœ… PremiÃ¨res constatations significatives sur la trajectoire des glycÃ©mies
TrÃ¨s vite, on intÃ©gre et on mÃ©morise les quantitÃ©s d'aliments constitutifs des repas et les apports des produits en termes nutritionnels. Cette connaissance conduit Ã  composer des repas Ã©quilibrÃ©s. Cet Ã©quilibre est une variable trÃ¨s influente sur la limitation des pics glycÃ©miques. Mes glycÃ©mies postprandiales ont chutÃ© de l'ordre de 30% au bout d'une semaine. En fait, tout se passe comme si pour prendre des actions efficaces, il suffit de prendre des mesures. En somme, **Pour prendre des mesures, prenez des mesures **!

## ğŸ›  PrÃ©paration des donnÃ©es
```python
Importer les bibliothÃ¨ques nÃ©cessaires
import os, sys
import pandas as pd
import numpy as np
import joblib
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import torch
import torch.nn as nn
import torch.optim as optim
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
```
### ğŸ›  Chargement et nettoyage des donnÃ©es
```python
# Charger les donnÃ©es
data = pd.read_csv("Fichier.csv", sep=None, engine="python", decimal=",") #Votre Fichier.csv

# Nettoyage
for col in data.columns:
    if data[col].dtype == "object":
        data[col] = data[col].str.strip().str.replace(',', '.').astype(float)
```

### ğŸ“Š Visualisation des corrÃ©lations entre features
```python
import seaborn as sns
import matplotlib.pyplot as plt

corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm")
plt.show()
```

![Illustration](logs/Figure_1.png) 
---CorrÃ©lation entre lesÂ features---

Nous constatons une corrÃ©lation faible entre les donnÃ©es.

### ğŸ¯ Choix des variables et normalisation

```python
X = data[['Kcal', 'PRO', 'GLU', 'LIP', 'IG', 'CG', 'GPR']]
y = data['GPO']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

## 2. ğŸ‰ Essais d'entraÃ®nement de quelques modÃ¨les
ğŸ“Š RÃ©gression LinÃ©aire (Baseline)
```python
model_gl = LinearRegression()
model_gl.fit(X_scaled, y)
y_pred = model_gl.predict(X_scaled)

print("MSE:", mean_squared_error(y, y_pred))
print("R2:", r2_score(y, y_pred))
```

âš ï¸ ProblÃ¨meÂ : Score RÂ² = -1.7 est un trÃ¨s mauvais scoreÂ !
Un bon modÃ¨le doit avoir un RÂ² proche de 1 (1 signifie une prÃ©diction parfaite). Un RÂ² nÃ©gatif signifie que le modÃ¨le est pire qu'une simple moyenne des valeurs observÃ©es. Au vu de la faible corrÃ©lation entre les donnÃ©es, ce rÃ©sultat n'est pas surprenant.

ğŸ’¡XGBoost
```python
model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
model_xgb.fit(X_scaled, y)
y_pred_xgb = model_xgb.predict(X_scaled)
```
âŒ **RÃ©sultat dÃ©cevant** (RÂ² nÃ©gatif), donc pas adaptÃ© non plus pour notre problÃ¨me.

ğŸŒŸ Random Forest
```python
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_scaled, y)
y_pred_rf = model_rf.predict(X_scaled)
```
âš ï¸AmÃ©liorationÂ : RÂ² passe Ã  0.36
Les modÃ¨les statistiques se sont avÃ©rÃ©s peu indiquÃ©s pour traiter ce problÃ¨me, nous nous sommes donc tournÃ©s vers les rÃ©seaux de neurones.

## 3.ğŸ” Entrainement d'un rÃ©seau de neurones avec PyTorch
```python
import torch
import torch.nn as nn
import torch.optim as optim

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(X_scaled.shape[1], 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        return self.fc3(x)

# Initialisation
model_nn = NeuralNetwork()
criterion = nn.MSELoss()
optimizer = optim.Adam(model_nn.parameters(), lr=0.001)

# EntraÃ®nement
num_epochs = 500
for epoch in range(num_epochs):
    model_nn.train()
    optimizer.zero_grad()
    outputs = model_nn(torch.tensor(X_scaled, dtype=torch.float32))
    loss = criterion(outputs, torch.tensor(y.values, dtype=torch.float32).view(-1, 1))
    loss.backward()
    optimizer.step()

    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss. Item():.4f}')
```
âœ… Le rÃ©seau de neurones a donnÃ© les meilleurs rÃ©sultatsÂ !
Comme hyperparamÃ¨tres, ceux qui conduisent au meilleur profil de la loss sont dans notre casÂ : num_epochs = 500 et learning-rate = 0,001. Le profil de la loss suggÃ¨re que le modÃ¨le apprend bien.

ğŸ”Les premiers rÃ©sultats obtenus montrent une prÃ©valence des protÃ©ines sur les autres facteurs sur la glycÃ©mie postprandiale (GPO). Ils semblent suggÃ©rer aussi que le contrÃ´le de la glycÃ©mie repose sur un Ã©quilibre entre protÃ©ines et glucides. L'objectif des prochaines Ã©tapes de ce projet est de confirmer ce rÃ©sultat et de le quantifier.

## 4. ğŸ›  CrÃ©ation de l'application Streamlit
Une application streamlit a Ã©tÃ© dÃ©veloppÃ©e afin de saisir et de soumettre les paramÃ¨res GLU, PRO, LIP, IG, CG, GPR afin de prÃ©dire GPO, glycÃ©mie postprandiale.
```python
st.title("PrÃ©diction de la GlycÃ©mie Postprandiale")
GLU = st.number_input("Glucides")
PRO = st.number_input("ProtÃ©ines")
LIP = st.number_input("Lipides")
IG = st.number_input("Indice GlycÃ©mique")
CG = st.number_input("Charge GlycÃ©mique")
GPR = st.number_input("GlycÃ©mie PrÃ©pandriale")

if st.button("PrÃ©dire"):
    input_data = torch.tensor([[GLU, PRO, LIP, IG, CG, GPR]], dtype=torch.float32)
    prediction = model_nn(input_data).item()
    st.success(f"GlycÃ©mie postprandiale prÃ©dite : {prediction:.2f} mg/dL")
```

âœ… Les prÃ©visions sont conformes aux mesures de glycÃ©mie rÃ©alisÃ©es aprÃ¨s les repas.

## ğŸ” Conclusion
âœ… Les rÃ©seaux de neurones sont adaptÃ©s Ã  ce domaine. Parmi tous les modÃ¨les expÃ©rimentÃ©s, ils sont les plus performants et prometteurs.

âœ… Des rÃ©sultats encourageants
Bien que les modÃ¨les soient perfectibles, principalement en enrichissant le dataset, les premiers rÃ©sultats sont encourageants. Les glycÃ©mies prÃ©dites sont conformes Ã  celles qui sont effectivement mesurÃ©es.
L'IA peut apporter des avancÃ©es remarquables dans ce domaine de santÃ© publique, en dÃ©couvrant d'autres pistes pour accompagner les personnes DT1 ou DT2, notamment autour de l'Ã©quilibre des repas et pas seulement en adoptant des rÃ©gimes restrictifs et trÃ¨s contraignants de limitation de tel ou tel type d'aliments.

âœ… NÃ©cessitÃ© d'augmenter et de diversifier les donnÃ©es
Comme l'expÃ©rience est menÃ©e Ã  partir des donnÃ©es d'une seule personne, qui s'alimente de faÃ§on Ã©quilibrÃ©e, sans excÃ¨s et Ã  heures fixes, qui s'adonne de plus Ã  une activitÃ© sportive rÃ©guliÃ¨re, donc sujet Ã  une errance glycÃ©mique modÃ©rÃ©e, les donnÃ©es GPO ne varient pas Ã©normÃ©ment entre les repas. Le modÃ¨le a tendance Ã  prÃ©dire des valeurs qui sont voisines des donnÃ©es d'entrainement. Il faudrait donc tester avec d'autres profils de personnes pour dÃ©terminer la capacitÃ© de gÃ©nÃ©ralisation du modÃ¨le. C'est l'objectif des phases ultÃ©rieures de ce projet.

âœ… Prochaines Ã©tapesÂ ?
- AmÃ©liorer l'entraÃ®nement du rÃ©seau neuronal avec plus de donnÃ©esÂ ! ğŸš€
- Augmenter le nombre de features (horaire des repas, activitÃ© physique) et amÃ©liorer la quantitÃ© et la qualitÃ© des donnÃ©es.

A ce sujet, je fais un appel pour constituer une communautÃ© motivÃ©e pour enrichir le dataset, qui serait public et anonyme.